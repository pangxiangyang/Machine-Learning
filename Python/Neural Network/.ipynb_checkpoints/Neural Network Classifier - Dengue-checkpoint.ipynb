{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year    Week  Cases  Rainfalls  No.of Raindays  Max. temperature  \\\n",
      "0    2010   week1    NaN        NaN             NaN               NaN   \n",
      "1    2010   week2    NaN        NaN             NaN               NaN   \n",
      "2    2010   week3    NaN        NaN             NaN               NaN   \n",
      "3    2010   week4    NaN      286.0            22.0         32.883871   \n",
      "4    2010   week5    NaN        NaN             NaN               NaN   \n",
      "5    2010   week6    NaN        NaN             NaN               NaN   \n",
      "6    2010   week7    NaN        NaN             NaN               NaN   \n",
      "7    2010   week8   36.0      241.8            11.0         34.385714   \n",
      "8    2010   week9   65.0        NaN             NaN               NaN   \n",
      "9    2010  week10   46.0        NaN             NaN               NaN   \n",
      "10   2010  week11   31.0        NaN             NaN               NaN   \n",
      "11   2010  week12   27.0      191.8            14.0         34.338710   \n",
      "12   2010  week13   40.0        NaN             NaN               NaN   \n",
      "13   2010  week14   49.0        NaN             NaN               NaN   \n",
      "14   2010  week15   29.0        NaN             NaN               NaN   \n",
      "15   2010  week16   38.0      304.2            19.0         33.456667   \n",
      "16   2010  week17   40.0        NaN             NaN               NaN   \n",
      "17   2010  week18   38.0        NaN             NaN               NaN   \n",
      "18   2010  week19   33.0        NaN             NaN               NaN   \n",
      "19   2010  week20   37.0      366.4            18.0         33.493548   \n",
      "20   2010  week21   38.0        NaN             NaN               NaN   \n",
      "21   2010  week22   54.0        NaN             NaN               NaN   \n",
      "22   2010  week23   78.0        NaN             NaN               NaN   \n",
      "23   2010  week24   66.0      303.0            21.0         32.776667   \n",
      "24   2010  week25   78.0        NaN             NaN               NaN   \n",
      "25   2010  week26   63.0        NaN             NaN               NaN   \n",
      "26   2010  week27   56.0        NaN             NaN               NaN   \n",
      "27   2010  week28   38.0      173.8            15.0         32.629032   \n",
      "28   2010  week29   93.0        NaN             NaN               NaN   \n",
      "29   2010  week30   65.0        NaN             NaN               NaN   \n",
      "..    ...     ...    ...        ...             ...               ...   \n",
      "282  2015  week23    NaN        NaN             NaN               NaN   \n",
      "283  2015  week24    NaN      131.4            11.0         33.260000   \n",
      "284  2015  week25    NaN        NaN             NaN               NaN   \n",
      "285  2015  week26    NaN        NaN             NaN               NaN   \n",
      "286  2015  week27    NaN        NaN             NaN               NaN   \n",
      "287  2015  week28    NaN      115.6            14.0         33.538710   \n",
      "288  2015  week29    NaN        NaN             NaN               NaN   \n",
      "289  2015  week30    NaN        NaN             NaN               NaN   \n",
      "290  2015  week31    NaN        NaN             NaN               NaN   \n",
      "291  2015  week32    NaN       99.0            17.0         33.000000   \n",
      "292  2015  week33    NaN        NaN             NaN               NaN   \n",
      "293  2015  week34    NaN        NaN             NaN               NaN   \n",
      "294  2015  week35    NaN        NaN             NaN               NaN   \n",
      "295  2015  week36    NaN      135.2            14.0         32.670000   \n",
      "296  2015  week37    NaN        NaN             NaN               NaN   \n",
      "297  2015  week38    NaN        NaN             NaN               NaN   \n",
      "298  2015  week39    NaN        NaN             NaN               NaN   \n",
      "299  2015  week40    NaN      134.0            18.0         31.929032   \n",
      "300  2015  week41    NaN        NaN             NaN               NaN   \n",
      "301  2015  week42    NaN        NaN             NaN               NaN   \n",
      "302  2015  week43    NaN        NaN             NaN               NaN   \n",
      "303  2015  week44    NaN      487.2            25.0         31.946667   \n",
      "304  2015  week45    NaN        NaN             NaN               NaN   \n",
      "305  2015  week46    NaN        NaN             NaN               NaN   \n",
      "306  2015  week47    NaN        NaN             NaN               NaN   \n",
      "307  2015  week48    NaN      180.0            22.0         32.748387   \n",
      "308  2015  week49    NaN        NaN             NaN               NaN   \n",
      "309  2015  week50    NaN        NaN             NaN               NaN   \n",
      "310  2015  week51    NaN        NaN             NaN               NaN   \n",
      "311  2015  week52    NaN        NaN             NaN               NaN   \n",
      "\n",
      "     Min. temperature  Mean temp  Fatality  \n",
      "0                 NaN        NaN       NaN  \n",
      "1                 NaN        NaN       NaN  \n",
      "2                 NaN        NaN       NaN  \n",
      "3           23.751613  26.945161       NaN  \n",
      "4                 NaN        NaN       NaN  \n",
      "5                 NaN        NaN       NaN  \n",
      "6                 NaN        NaN       NaN  \n",
      "7           24.535714  28.382143       NaN  \n",
      "8                 NaN        NaN       NaN  \n",
      "9                 NaN        NaN       NaN  \n",
      "10                NaN        NaN       NaN  \n",
      "11          24.470968  28.254839       NaN  \n",
      "12                NaN        NaN       NaN  \n",
      "13                NaN        NaN       1.0  \n",
      "14                NaN        NaN       NaN  \n",
      "15          24.576667  27.926667       NaN  \n",
      "16                NaN        NaN       1.0  \n",
      "17                NaN        NaN       NaN  \n",
      "18                NaN        NaN       NaN  \n",
      "19          24.800000  28.287097       NaN  \n",
      "20                NaN        NaN       NaN  \n",
      "21                NaN        NaN       NaN  \n",
      "22                NaN        NaN       1.0  \n",
      "23          23.873333  27.310000       1.0  \n",
      "24                NaN        NaN       NaN  \n",
      "25                NaN        NaN       NaN  \n",
      "26                NaN        NaN       NaN  \n",
      "27          23.851613  27.232258       NaN  \n",
      "28                NaN        NaN       1.0  \n",
      "29                NaN        NaN       NaN  \n",
      "..                ...        ...       ...  \n",
      "282               NaN        NaN       NaN  \n",
      "283         24.840000  28.266667       NaN  \n",
      "284               NaN        NaN       NaN  \n",
      "285               NaN        NaN       NaN  \n",
      "286               NaN        NaN       NaN  \n",
      "287         24.509677  28.032258       NaN  \n",
      "288               NaN        NaN       NaN  \n",
      "289               NaN        NaN       NaN  \n",
      "290               NaN        NaN       NaN  \n",
      "291         24.309677  27.587097       NaN  \n",
      "292               NaN        NaN       NaN  \n",
      "293               NaN        NaN       NaN  \n",
      "294               NaN        NaN       NaN  \n",
      "295         24.316667  27.623333       NaN  \n",
      "296               NaN        NaN       NaN  \n",
      "297               NaN        NaN       NaN  \n",
      "298               NaN        NaN       NaN  \n",
      "299         24.054839  26.864516       NaN  \n",
      "300               NaN        NaN       NaN  \n",
      "301               NaN        NaN       NaN  \n",
      "302               NaN        NaN       NaN  \n",
      "303         23.563333  26.326667       NaN  \n",
      "304               NaN        NaN       NaN  \n",
      "305               NaN        NaN       NaN  \n",
      "306               NaN        NaN       NaN  \n",
      "307         23.625806  26.948387       NaN  \n",
      "308               NaN        NaN       NaN  \n",
      "309               NaN        NaN       NaN  \n",
      "310               NaN        NaN       NaN  \n",
      "311               NaN        NaN       NaN  \n",
      "\n",
      "[312 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import raw data from Excel\n",
    "import pandas as pd\n",
    "\n",
    "filepath = 'C:/Users/PXY/Desktop/Orange_week.xlsx';\n",
    "sheetname = 'main'\n",
    "df = pd.read_excel ( filepath, sheet_name = sheetname );\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "# Set NaN to 0.0 for Cases & Fatality\n",
    "df['Cases'].fillna( 0, inplace = True )\n",
    "df['Fatality'].fillna(0, inplace = True )\n",
    "\n",
    "# Set others to first found values\n",
    "df['Rainfalls'].ffill( inplace = True );\n",
    "df['Max. temperature'].ffill( inplace = True );\n",
    "df['Min. temperature'].ffill( inplace = True );\n",
    "df['Mean temp'].ffill( inplace = True );\n",
    "\n",
    "# Ffill doesn't fill in the first three NaN, thus need to do another bfill\n",
    "df['Rainfalls'].bfill( inplace = True );\n",
    "df['Max. temperature'].bfill( inplace = True );\n",
    "df['Min. temperature'].bfill( inplace = True );\n",
    "df['Mean temp'].bfill( inplace = True );\n",
    "\n",
    "# Add new target columns\n",
    "df['FatalityRate'] = (df['Fatality'] > 0).astype(int)\n",
    "df['HasCase'] = (df['Cases'] > 0).astype(int)\n",
    "\n",
    "# Drop unused columns: no.of rain days, Week, Year\n",
    "if 'No.of Raindays' in df.columns:\n",
    "    df = df.drop(['No.of Raindays'], axis = 1 )\n",
    "\n",
    "if 'Year' in df.columns:\n",
    "    df = df.drop(['Year'], axis = 1 )\n",
    "\n",
    "if 'Week' in df.columns:\n",
    "    df = df.drop(['Week'], axis = 1 )\n",
    "\n",
    "if 'Fatality' in df.columns:\n",
    "    df = df.drop(['Fatality'], axis = 1 )\n",
    "    \n",
    "# Verify if all the anomalies are gone\n",
    "df.describe()\n",
    "\n",
    "# Write to output csv for data visualization purpose\n",
    "df.to_csv('C:/Users/PXY/Desktop/dengue.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "# This step is really useful on improving model performance\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "cols_to_norm = [ 'Rainfalls','Max. temperature','Min. temperature','Mean temp']\n",
    "#df[cols_to_norm] = StandardScaler().fit_transform(df[cols_to_norm])\n",
    "\n",
    "# Create predictors\n",
    "predictors = df.drop(['HasCase','FatalityRate'], axis=1).values\n",
    "n_cols = predictors.shape[1] \n",
    "  \n",
    "# Create target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "target = label_encoder.fit_transform(df.HasCase)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, \n",
    "                                                    test_size=0.3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PXY\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\PXY\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "acc: 100.00%\n",
      "acc: 100.00%\n",
      "acc: 100.00%\n",
      "acc: 100.00%\n",
      "acc: 100.00%\n",
      "100.00% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Build and train the model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "import numpy as py\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "py.random.seed(seed)\n",
    "cvscores = []\n",
    "\n",
    "# define 10-fold cross validation test harness\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "for train, test in kfold.split(predictors, target):\n",
    "    \n",
    "  # Input layer\n",
    "  model = keras.Sequential() \n",
    "  model.add(layers.Dense(100, activation='relu', input_shape = (n_cols,))) \n",
    "  model.add(layers.Dense(100, activation='relu')) \n",
    "\n",
    "  # Output layer\n",
    "  model.add(layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "  # Compile model\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "  # Fit the model\n",
    "  model.fit(predictors[train], target[train], epochs=40,  verbose=False )\n",
    "  # evaluate the model\n",
    "  scores = model.evaluate(predictors[test], target[test], verbose=0)\n",
    "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "  cvscores.append(scores[1] * 100)\n",
    "\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (py.mean(cvscores), py.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
