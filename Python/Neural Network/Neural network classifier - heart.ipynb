{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Es3kw9OJg1uV"
   },
   "source": [
    "##2. What type of problem are we trying to solve here? Classification or regression?\n",
    "Classification, to identify if the patient is exposed to heart disease or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uoHG5ihng1uf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0     63    1   3       145   233    1        0      150      0      2.3   \n",
      "1     37    1   2       130   250    0        1      187      0      3.5   \n",
      "2     41    0   1       130   204    0        0      172      0      1.4   \n",
      "3     56    1   1       120   236    0        1      178      0      0.8   \n",
      "4     57    0   0       120   354    0        1      163      1      0.6   \n",
      "5     57    1   0       140   192    0        1      148      0      0.4   \n",
      "6     56    0   1       140   294    0        0      153      0      1.3   \n",
      "7     44    1   1       120   263    0        1      173      0      0.0   \n",
      "8     52    1   2       172   199    1        1      162      0      0.5   \n",
      "9     57    1   2       150   168    0        1      174      0      1.6   \n",
      "10    54    1   0       140   239    0        1      160      0      1.2   \n",
      "11    48    0   2       130   275    0        1      139      0      0.2   \n",
      "12    49    1   1       130   266    0        1      171      0      0.6   \n",
      "13    64    1   3       110   211    0        0      144      1      1.8   \n",
      "14    58    0   3       150   283    1        0      162      0      1.0   \n",
      "15    50    0   2       120   219    0        1      158      0      1.6   \n",
      "16    58    0   2       120   340    0        1      172      0      0.0   \n",
      "17    66    0   3       150   226    0        1      114      0      2.6   \n",
      "18    43    1   0       150   247    0        1      171      0      1.5   \n",
      "19    69    0   3       140   239    0        1      151      0      1.8   \n",
      "20    59    1   0       135   234    0        1      161      0      0.5   \n",
      "21    44    1   2       130   233    0        1      179      1      0.4   \n",
      "22    42    1   0       140   226    0        1      178      0      0.0   \n",
      "23    61    1   2       150   243    1        1      137      1      1.0   \n",
      "24    40    1   3       140   199    0        1      178      1      1.4   \n",
      "25    71    0   1       160   302    0        1      162      0      0.4   \n",
      "26    59    1   2       150   212    1        1      157      0      1.6   \n",
      "27    51    1   2       110   175    0        1      123      0      0.6   \n",
      "28    65    0   2       140   417    1        0      157      0      0.8   \n",
      "29    53    1   2       130   197    1        0      152      0      1.2   \n",
      "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
      "273   58    1   0       100   234    0        1      156      0      0.1   \n",
      "274   47    1   0       110   275    0        0      118      1      1.0   \n",
      "275   52    1   0       125   212    0        1      168      0      1.0   \n",
      "276   58    1   0       146   218    0        1      105      0      2.0   \n",
      "277   57    1   1       124   261    0        1      141      0      0.3   \n",
      "278   58    0   1       136   319    1        0      152      0      0.0   \n",
      "279   61    1   0       138   166    0        0      125      1      3.6   \n",
      "280   42    1   0       136   315    0        1      125      1      1.8   \n",
      "281   52    1   0       128   204    1        1      156      1      1.0   \n",
      "282   59    1   2       126   218    1        1      134      0      2.2   \n",
      "283   40    1   0       152   223    0        1      181      0      0.0   \n",
      "284   61    1   0       140   207    0        0      138      1      1.9   \n",
      "285   46    1   0       140   311    0        1      120      1      1.8   \n",
      "286   59    1   3       134   204    0        1      162      0      0.8   \n",
      "287   57    1   1       154   232    0        0      164      0      0.0   \n",
      "288   57    1   0       110   335    0        1      143      1      3.0   \n",
      "289   55    0   0       128   205    0        2      130      1      2.0   \n",
      "290   61    1   0       148   203    0        1      161      0      0.0   \n",
      "291   58    1   0       114   318    0        2      140      0      4.4   \n",
      "292   58    0   0       170   225    1        0      146      1      2.8   \n",
      "293   67    1   2       152   212    0        0      150      0      0.8   \n",
      "294   44    1   0       120   169    0        1      144      1      2.8   \n",
      "295   63    1   0       140   187    0        0      144      1      4.0   \n",
      "296   63    0   0       124   197    0        1      136      1      0.0   \n",
      "297   59    1   0       164   176    1        0       90      0      1.0   \n",
      "298   57    0   0       140   241    0        1      123      1      0.2   \n",
      "299   45    1   3       110   264    0        1      132      0      1.2   \n",
      "300   68    1   0       144   193    1        1      141      0      3.4   \n",
      "301   57    1   0       130   131    0        1      115      1      1.2   \n",
      "302   57    0   1       130   236    0        0      174      0      0.0   \n",
      "\n",
      "     slope  ca  thal  target  \n",
      "0        0   0     1       1  \n",
      "1        0   0     2       1  \n",
      "2        2   0     2       1  \n",
      "3        2   0     2       1  \n",
      "4        2   0     2       1  \n",
      "5        1   0     1       1  \n",
      "6        1   0     2       1  \n",
      "7        2   0     3       1  \n",
      "8        2   0     3       1  \n",
      "9        2   0     2       1  \n",
      "10       2   0     2       1  \n",
      "11       2   0     2       1  \n",
      "12       2   0     2       1  \n",
      "13       1   0     2       1  \n",
      "14       2   0     2       1  \n",
      "15       1   0     2       1  \n",
      "16       2   0     2       1  \n",
      "17       0   0     2       1  \n",
      "18       2   0     2       1  \n",
      "19       2   2     2       1  \n",
      "20       1   0     3       1  \n",
      "21       2   0     2       1  \n",
      "22       2   0     2       1  \n",
      "23       1   0     2       1  \n",
      "24       2   0     3       1  \n",
      "25       2   2     2       1  \n",
      "26       2   0     2       1  \n",
      "27       2   0     2       1  \n",
      "28       2   1     2       1  \n",
      "29       0   0     2       1  \n",
      "..     ...  ..   ...     ...  \n",
      "273      2   1     3       0  \n",
      "274      1   1     2       0  \n",
      "275      2   2     3       0  \n",
      "276      1   1     3       0  \n",
      "277      2   0     3       0  \n",
      "278      2   2     2       0  \n",
      "279      1   1     2       0  \n",
      "280      1   0     1       0  \n",
      "281      1   0     0       0  \n",
      "282      1   1     1       0  \n",
      "283      2   0     3       0  \n",
      "284      2   1     3       0  \n",
      "285      1   2     3       0  \n",
      "286      2   2     2       0  \n",
      "287      2   1     2       0  \n",
      "288      1   1     3       0  \n",
      "289      1   1     3       0  \n",
      "290      2   1     3       0  \n",
      "291      0   3     1       0  \n",
      "292      1   2     1       0  \n",
      "293      1   0     3       0  \n",
      "294      0   0     1       0  \n",
      "295      2   2     3       0  \n",
      "296      1   0     2       0  \n",
      "297      1   2     1       0  \n",
      "298      1   0     3       0  \n",
      "299      1   0     3       0  \n",
      "300      1   2     3       0  \n",
      "301      1   1     3       0  \n",
      "302      1   1     2       0  \n",
      "\n",
      "[303 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "#Question3\n",
    "\n",
    "import numpy as py\n",
    "import pandas as pd\n",
    "\n",
    "#Mount google drive\n",
    "#from google.colab import drive \n",
    "#drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "#Read the file from google drive\n",
    "#data = pd.read_csv( 'gdrive/My Drive/Machine Learning Playground/heart.csv' )\n",
    "data = pd.read_csv('C:\\\\Users\\\\PXY\\\\Desktop\\\\heart.csv');\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9au-NypiLgA"
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "GPU sync failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: GPU sync failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-aecf857b6964>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping_monitor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# Evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;31m# Setup work for each epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1117\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'metrics'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1119\u001b[1;33m         \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1120\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[0mtraining_distributed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m     \"\"\"\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m       \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mset_value\u001b[1;34m(x, value)\u001b[0m\n\u001b[0;32m   2845\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2846\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2847\u001b[1;33m       \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    480\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m       \u001b[0m_initialize_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[1;34m(session)\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[1;31m# marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m     is_initialized = session.run(\n\u001b[1;32m--> 758\u001b[1;33m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[0;32m    759\u001b[0m     \u001b[0muninitialized_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: GPU sync failed"
     ]
    }
   ],
   "source": [
    "# Normalizing data\n",
    "# This step is really useful on improving model performance\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "cols_to_norm = ['age','chol','trestbps','thalach','oldpeak']\n",
    "data[cols_to_norm] = StandardScaler().fit_transform(data[cols_to_norm])\n",
    "\n",
    "# Create predictors\n",
    "predictors = data.drop(['target'], axis=1).values\n",
    "n_cols = predictors.shape[1] \n",
    "  \n",
    "# Create target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "target = label_encoder.fit_transform(data.target)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, \n",
    "                                                    test_size=0.3 )\n",
    "\n",
    "# Build and train the model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "\n",
    "# Input layer\n",
    "model = keras.Sequential() \n",
    "model.add(layers.Dense(100, activation='relu', input_shape = (n_cols,))) \n",
    "model.add(layers.Dense(100, activation='relu', input_shape = (n_cols,))) \n",
    "model.add(layers.Dense(100, activation='relu', input_shape = (n_cols,))) \n",
    "model.add(layers.Dense(100, activation='relu', input_shape = (n_cols,))) \n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "#Define early stopping to stop training if model didn't improved for 2 epochs\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=5, monitor = 'acc')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=40, verbose=1, callbacks=[early_stopping_monitor] )\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pg4JLPJQ6-xQ"
   },
   "source": [
    "##Epoch 20/40\n",
    "Epoch 20/40\n",
    "212/212 [==============================] - 0s 157us/sample - loss: 0.0571 - acc: 0.9906\n",
    "Accuracy at Epoch20 is 0.9906 or 99.06%\n",
    "\n",
    "Due to the randomness during the training of model, the accuracy might be different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 99424,
     "status": "ok",
     "timestamp": 1555262768901,
     "user": {
      "displayName": "pang xiang yang",
      "photoUrl": "https://lh4.googleusercontent.com/-JoCF5wddXug/AAAAAAAAAAI/AAAAAAAAAMc/59mWt-LDqzU/s64/photo.jpg",
      "userId": "02898871159931083107"
     },
     "user_tz": -480
    },
    "id": "Z9VSkxMWrcGA",
    "outputId": "845251af-5724-431b-a782-0545856513dd"
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "py.random.seed(seed)\n",
    "cvscores = []\n",
    "\n",
    "# define 10-fold cross validation test harness\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "for train, test in kfold.split(predictors, target):\n",
    "  # Input layer\n",
    "  model = keras.Sequential() \n",
    "  model.add(layers.Dense(100, activation='relu', input_shape = (n_cols,))) \n",
    "  model.add(layers.Dense(100, activation='relu')) \n",
    "\n",
    "  # Output layer\n",
    "  model.add(layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "  # Compile model\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "  # Fit the model\n",
    "  model.fit(predictors[train], target[train], epochs=40,  verbose=False )\n",
    "  # evaluate the model\n",
    "  scores = model.evaluate(predictors[test], target[test], verbose=0)\n",
    "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "  cvscores.append(scores[1] * 100)\n",
    "\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (py.mean(cvscores), py.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5S_ktvZg1ui"
   },
   "source": [
    "#4. What is underfitting and overfitting?\n",
    "Underfitting : the model is not train enough and unable to identify / detect any useful pattern from the input data\n",
    "Overfitting  : the model is over trained / fully adapted to the input data, thus it is very sensitive to the changes of input data and not really useful in prediction where the input data is differ to the training data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTVPeqgGg1uj"
   },
   "source": [
    "#5. Explain how you can reduce the overfitting of the model\n",
    "To reduce overfitting of data, K-fold cross validation / splitting the data into training and validation will help to validate the model. By doing K-fold cross validation, data will be splitted into multiple set of test & train and repeated multiple times. Each time, the test & train data will be shuffled, thus preventing the model from overfitting by introducing data in various form.\n",
    "\n",
    "Splitting the training data into training and validation only application at big dataset,"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of Quiz2-Pang.ipynb",
   "provenance": [
    {
     "file_id": "1otr1msYBqEcU0nXOvfLJ5eKEVQ9M-nQw",
     "timestamp": 1555263931245
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
