{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Rainfalls</th>\n",
       "      <th>No.of Raindays</th>\n",
       "      <th>Max. temperature</th>\n",
       "      <th>Min. temperature</th>\n",
       "      <th>Mean temp</th>\n",
       "      <th>Fatality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>312.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2012.500000</td>\n",
       "      <td>64.496000</td>\n",
       "      <td>223.080556</td>\n",
       "      <td>16.291667</td>\n",
       "      <td>32.853582</td>\n",
       "      <td>23.953182</td>\n",
       "      <td>27.318545</td>\n",
       "      <td>1.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.710569</td>\n",
       "      <td>75.747798</td>\n",
       "      <td>122.884753</td>\n",
       "      <td>5.605424</td>\n",
       "      <td>0.893736</td>\n",
       "      <td>0.466414</td>\n",
       "      <td>0.708983</td>\n",
       "      <td>0.470929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.664516</td>\n",
       "      <td>22.812903</td>\n",
       "      <td>25.712903</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>32.259677</td>\n",
       "      <td>23.668548</td>\n",
       "      <td>26.773145</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2012.500000</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>32.916129</td>\n",
       "      <td>23.880215</td>\n",
       "      <td>27.225806</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>64.750000</td>\n",
       "      <td>318.875000</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>33.394167</td>\n",
       "      <td>24.253226</td>\n",
       "      <td>27.936129</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>489.200000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>35.267742</td>\n",
       "      <td>25.060000</td>\n",
       "      <td>28.816667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Year       Cases   Rainfalls  No.of Raindays  Max. temperature  \\\n",
       "count   312.000000  250.000000   72.000000       72.000000         72.000000   \n",
       "mean   2012.500000   64.496000  223.080556       16.291667         32.853582   \n",
       "std       1.710569   75.747798  122.884753        5.605424          0.893736   \n",
       "min    2010.000000   10.000000   18.200000        2.000000         30.664516   \n",
       "25%    2011.000000   28.000000  129.000000       13.000000         32.259677   \n",
       "50%    2012.500000   38.500000  201.000000       16.000000         32.916129   \n",
       "75%    2014.000000   64.750000  318.875000       20.250000         33.394167   \n",
       "max    2015.000000  495.000000  489.200000       26.000000         35.267742   \n",
       "\n",
       "       Min. temperature  Mean temp   Fatality  \n",
       "count         72.000000  72.000000  32.000000  \n",
       "mean          23.953182  27.318545   1.187500  \n",
       "std            0.466414   0.708983   0.470929  \n",
       "min           22.812903  25.712903   1.000000  \n",
       "25%           23.668548  26.773145   1.000000  \n",
       "50%           23.880215  27.225806   1.000000  \n",
       "75%           24.253226  27.936129   1.000000  \n",
       "max           25.060000  28.816667   3.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import raw data from Excel\n",
    "import pandas as pd\n",
    "\n",
    "filepath = 'C:/Users/PXY/Desktop/Orange_week.xlsx';\n",
    "sheetname = 'main'\n",
    "df = pd.read_excel ( filepath, sheet_name = sheetname );\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Year     Cases  Rainfalls  No.of Raindays  \\\n",
      "Year              1.000000  0.206160  -0.186199       -0.095696   \n",
      "Cases             0.206160  1.000000   0.146976        0.109804   \n",
      "Rainfalls        -0.186199  0.146976   1.000000        0.549997   \n",
      "No.of Raindays   -0.095696  0.109804   0.549997        1.000000   \n",
      "Max. temperature  0.118377 -0.291792  -0.385972       -0.627464   \n",
      "Min. temperature  0.179053 -0.241280  -0.274385       -0.388308   \n",
      "Mean temp         0.143124 -0.282314  -0.438190       -0.694038   \n",
      "Fatality          0.091511  0.495949   0.114988        0.058604   \n",
      "\n",
      "                  Max. temperature  Min. temperature  Mean temp  Fatality  \n",
      "Year                      0.118377          0.179053   0.143124  0.091511  \n",
      "Cases                    -0.291792         -0.241280  -0.282314  0.495949  \n",
      "Rainfalls                -0.385972         -0.274385  -0.438190  0.114988  \n",
      "No.of Raindays           -0.627464         -0.388308  -0.694038  0.058604  \n",
      "Max. temperature          1.000000          0.649857   0.914075 -0.104453  \n",
      "Min. temperature          0.649857          1.000000   0.854215 -0.034532  \n",
      "Mean temp                 0.914075          0.854215   1.000000 -0.081658  \n",
      "Fatality                 -0.104453         -0.034532  -0.081658  1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "# Set NaN to 0.0 for Cases & Fatality\n",
    "df['Cases'].fillna( 0, inplace = True )\n",
    "df['Fatality'].fillna(0, inplace = True )\n",
    "\n",
    "# Set others to first found values\n",
    "df['Rainfalls'].ffill( inplace = True );\n",
    "df['Max. temperature'].ffill( inplace = True );\n",
    "df['Min. temperature'].ffill( inplace = True );\n",
    "df['Mean temp'].ffill( inplace = True );\n",
    "\n",
    "# Ffill doesn't fill in the first three NaN, thus need to do another bfill\n",
    "df['Rainfalls'].bfill( inplace = True );\n",
    "df['Max. temperature'].bfill( inplace = True );\n",
    "df['Min. temperature'].bfill( inplace = True );\n",
    "df['Mean temp'].bfill( inplace = True );\n",
    "\n",
    "print( df.corr() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter( df['Rainfalls'] ,df['Cases'], color=\"red\" )\n",
    "plt.title( \"Rainfalls vs Cases\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter( df['Max. temperature'] ,df['Cases'], color=\"blue\" )\n",
    "plt.title( \"Max temperature vs Cases\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter( df['Min. temperature'] ,df['Cases'], color=\"black\" )\n",
    "plt.title( \"Min temperature vs Cases\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new target columns\n",
    "df['FatalityRate'] = (df['Fatality'] > 0).astype(int)\n",
    "df['HasCase'] = (df['Cases'] > 0).astype(int)\n",
    "\n",
    "# Drop unused columns: no.of rain days, Week, Year\n",
    "if 'No.of Raindays' in df.columns:\n",
    "    df = df.drop(['No.of Raindays'], axis = 1 )\n",
    "\n",
    "if 'Year' in df.columns:\n",
    "    df = df.drop(['Year'], axis = 1 )\n",
    "\n",
    "if 'Week' in df.columns:\n",
    "    df = df.drop(['Week'], axis = 1 )\n",
    "\n",
    "if 'Fatality' in df.columns:\n",
    "    df = df.drop(['Fatality'], axis = 1 )\n",
    "\n",
    "# Since there is no case reported since 2015, drop 2015 data from time series prediction\n",
    "df.drop(df.tail(52).index,inplace=True) #drop bottom 52 which is data from 2015 \n",
    "    \n",
    "# Verify if all the anomalies are gone\n",
    "df.describe()\n",
    "\n",
    "# Write to output csv for data visualization purpose\n",
    "df.to_csv('C:/Users/PXY/Desktop/dengue.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "# This step is really useful on improving model performance\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "cols_to_norm = [ 'Rainfalls','Max. temperature','Min. temperature','Mean temp']\n",
    "sc = StandardScaler();\n",
    "df[cols_to_norm] = sc.fit_transform(df[cols_to_norm])\n",
    "\n",
    "# Create predictors\n",
    "predictors = df.drop(['HasCase','FatalityRate', 'Cases'], axis=1).values\n",
    "n_cols = predictors.shape[1] \n",
    "  \n",
    "# Create target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "target = label_encoder.fit_transform(df.HasCase)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, \n",
    "                                                    test_size=0.3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 92.45%\n",
      "acc: 92.45%\n",
      "acc: 94.23%\n",
      "acc: 92.16%\n",
      "acc: 98.04%\n",
      "93.87% (+/- 2.21%)\n"
     ]
    }
   ],
   "source": [
    "# Build and train the model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "import numpy as py\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "py.random.seed(seed)\n",
    "cvscores = []\n",
    "\n",
    "# define 10-fold cross validation test harness\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "for train, test in kfold.split(predictors, target):\n",
    "    \n",
    "  # Input layer\n",
    "  model = keras.Sequential() \n",
    "  model.add(layers.Dense(100, activation='relu', input_shape = (n_cols,))) \n",
    "  #model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(100, activation='relu')) \n",
    "  #model.add(layers.Dropout(0.5))\n",
    "\n",
    "  # Output layer\n",
    "  model.add(layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "  # Compile model\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "  # Fit the model\n",
    "  model.fit(predictors[train], target[train], epochs=40,  verbose=False )\n",
    "  # evaluate the model\n",
    "  scores = model.evaluate(predictors[test], target[test], verbose=0)\n",
    "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "  cvscores.append(scores[1] * 100)\n",
    "\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (py.mean(cvscores), py.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "182/182 [==============================] - 1s 3ms/sample - loss: 0.6260 - acc: 0.7802\n",
      "Epoch 2/40\n",
      "182/182 [==============================] - 0s 230us/sample - loss: 0.4673 - acc: 0.9396\n",
      "Epoch 3/40\n",
      "182/182 [==============================] - 0s 297us/sample - loss: 0.3736 - acc: 0.9396\n",
      "Epoch 4/40\n",
      "182/182 [==============================] - 0s 263us/sample - loss: 0.3084 - acc: 0.9396\n",
      "Epoch 5/40\n",
      "182/182 [==============================] - 0s 202us/sample - loss: 0.2743 - acc: 0.9396\n",
      "Epoch 6/40\n",
      "182/182 [==============================] - 0s 214us/sample - loss: 0.2605 - acc: 0.9396\n",
      "Epoch 7/40\n",
      "182/182 [==============================] - 0s 230us/sample - loss: 0.2475 - acc: 0.9396\n",
      "Predicition results from 70:30 train- test split is : 0.9230769230769231\n",
      "[[ 0  6]\n",
      " [ 0 72]]\n"
     ]
    }
   ],
   "source": [
    "#Define early stopping to stop training if model didn't improved for 2 epochs\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=5, monitor = 'acc')\n",
    "\n",
    "# Input layer\n",
    "model = keras.Sequential() \n",
    "model.add(layers.Dense(100, activation='relu', input_shape = (n_cols,))) \n",
    "model.add(layers.Dense(100, activation='relu')) \n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=40, verbose=1, callbacks=[early_stopping_monitor] )\n",
    "\n",
    "# calculate accuracy\n",
    "res = model.predict(X_test)\n",
    "res = py.around( res, 0 ).astype(int)\n",
    "\n",
    "import sklearn\n",
    "acc = sklearn.metrics.accuracy_score( res, y_test )\n",
    "print( \"Predicition results from 70:30 train- test split is :\", acc)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print( confusion_matrix(y_test, res) )\n",
    "\n",
    "      \n",
    "# Export result to csv\n",
    "hascases = py.empty(len(df) )\n",
    "hascases.fill(-1)\n",
    "hascases[ len(df) - len(res):] = res.ravel()\n",
    "\n",
    "fullresult = pd.DataFrame()\n",
    "fullresult[cols_to_norm] = df[cols_to_norm]\n",
    "fullresult['HasCases'] = df['HasCase']\n",
    "fullresult['PredictedHasCases'] = hascases\n",
    "fullresult.to_csv('C:/Users/PXY/Desktop/classifier_result.csv');\n",
    "\n",
    "\n",
    "# Visualize neural network\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='C:/Users/PXY/Desktop/classifier_model.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
